{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVViVDVmXyD2Tir2jTKyg/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fivetop/python/blob/master/DeepLearning_XOR_Example_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gUb-oePQHm2a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datetime import datetime \n",
        "\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def numerical_derivative(f, x):\n",
        "  delta_x = 1e-4\n",
        "  grad = np.zeros_like(x)\n",
        "    \n",
        "  it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "  \n",
        "  while not it.finished:\n",
        "      idx = it.multi_index        \n",
        "      tmp_val = x[idx]\n",
        "      x[idx] = float(tmp_val) + delta_x\n",
        "      fx1 = f(x) # f(x+delta_x)\n",
        "      \n",
        "      x[idx] = float(tmp_val) - delta_x \n",
        "      fx2 = f(x) # f(x-delta_x)\n",
        "      grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
        "      \n",
        "      x[idx] = tmp_val \n",
        "      it.iternext()   \n",
        "      \n",
        "  return grad"
      ],
      "metadata": {
        "id": "s0eEsi2rI4BA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def sigmoid(z):\n",
        "  return 1/ (1+np.exp(-z))\n"
      ],
      "metadata": {
        "id": "r8GKAu7_I61f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xor_xdata = np.array([ [0,0], [0,1], [1,0], [1,1] ])  \n",
        "xor_tdata = np.array([0, 1, 1, 0]).reshape(4,1)\n",
        "\n",
        "print(\"xor_xdata.shape = \", xor_xdata.shape, \", xor_tdata.shape = \", xor_tdata.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6sQUVZ2JDPm",
        "outputId": "2f7c3205-9287-4b2f-acbd-2ca62e38ba88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xor_xdata.shape =  (4, 2) , xor_tdata.shape =  (4, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_nodes = 2\n",
        "hidden_nodes = 3\n",
        "output_nodes = 1\n",
        "\n",
        "W2 = np.random.rand(input_nodes, hidden_nodes)\n",
        "W3 = np.random.rand(hidden_nodes, output_nodes)\n",
        "\n",
        "b2 = np.random.rand(hidden_nodes)\n",
        "b3 = np.random.rand(output_nodes)\n",
        "\n",
        "print(W2)\n",
        "print(b2)\n",
        "\n",
        "print(W3)\n",
        "print(b3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC-ahsazJJQ-",
        "outputId": "de875ce7-ae7e-41ce-c9ca-4378ab2b1a36"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.92559664 0.07103606 0.0871293 ]\n",
            " [0.0202184  0.83261985 0.77815675]]\n",
            "[0.46147936 0.78052918 0.11827443]\n",
            "[[0.87001215]\n",
            " [0.97861834]\n",
            " [0.79915856]]\n",
            "[0.63992102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(x, t):\n",
        "    \n",
        "    delta = 1e-7    # log 무한대 발산 방지\n",
        "    \n",
        "    z2 = np.dot(x, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    z3 = np.dot(a2, W3) + b3\n",
        "    y = a3 = sigmoid(z3)\n",
        "    \n",
        "    # cross-entropy \n",
        "    return  -np.sum( t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta ) ) \n",
        "\n",
        "    # MSE\n",
        "    #return np.sum((t-y)**2) / len(x)\n",
        "    "
      ],
      "metadata": {
        "id": "XZMkL8OmJ44n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-2  \n",
        "\n",
        "f = lambda x : loss_func(xor_xdata, xor_tdata)  \n",
        "\n",
        "print(\"Initial loss value = \", loss_func(xor_xdata, xor_tdata) )\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "for step in range(30001):  \n",
        "    \n",
        "    W2 -= learning_rate * numerical_derivative(f, W2)\n",
        "    \n",
        "    b2 -= learning_rate * numerical_derivative(f, b2)\n",
        "\n",
        "    W3 -= learning_rate * numerical_derivative(f, W3)\n",
        "    \n",
        "    b3 -= learning_rate * numerical_derivative(f, b3)\n",
        "    \n",
        "    if (step % 500 == 0):\n",
        "        print(\"step = \", step, \"loss value = \", loss_func(xor_xdata, xor_tdata) )\n",
        "        \n",
        "end_time = datetime.now()\n",
        "        \n",
        "print(\"\")\n",
        "print(\"Elapsed Time => \", end_time - start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb96vCacKVXl",
        "outputId": "b6d58ffd-abdf-4cc4-8dec-dcaa06f48392"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss value =  5.3306531689890555\n",
            "step =  0 loss value =  5.256152423251162\n",
            "step =  500 loss value =  2.7725393771912454\n",
            "step =  1000 loss value =  2.772075003684494\n",
            "step =  1500 loss value =  2.7715704397692242\n",
            "step =  2000 loss value =  2.770990268155099\n",
            "step =  2500 loss value =  2.7702888103739123\n",
            "step =  3000 loss value =  2.7694035230459946\n",
            "step =  3500 loss value =  2.768244801127125\n",
            "step =  4000 loss value =  2.766679796650152\n",
            "step =  4500 loss value =  2.7645064174871674\n",
            "step =  5000 loss value =  2.7614115128394627\n",
            "step =  5500 loss value =  2.756904230920022\n",
            "step =  6000 loss value =  2.750211329515637\n",
            "step =  6500 loss value =  2.7401143763877176\n",
            "step =  7000 loss value =  2.724696357344846\n",
            "step =  7500 loss value =  2.700957700760961\n",
            "step =  8000 loss value =  2.664359755467888\n",
            "step =  8500 loss value =  2.6088842413543665\n",
            "step =  9000 loss value =  2.529242325445814\n",
            "step =  9500 loss value =  2.425765897398958\n",
            "step =  10000 loss value =  2.306340924313462\n",
            "step =  10500 loss value =  2.1801790121616857\n",
            "step =  11000 loss value =  2.050282469723396\n",
            "step =  11500 loss value =  1.9122756275376056\n",
            "step =  12000 loss value =  1.758914207918076\n",
            "step =  12500 loss value =  1.5865694654959444\n",
            "step =  13000 loss value =  1.398770217367741\n",
            "step =  13500 loss value =  1.20458101767891\n",
            "step =  14000 loss value =  1.016176268873714\n",
            "step =  14500 loss value =  0.8457279944890149\n",
            "step =  15000 loss value =  0.7007943477972818\n",
            "step =  15500 loss value =  0.5827548973878068\n",
            "step =  16000 loss value =  0.4888029418126413\n",
            "step =  16500 loss value =  0.41459150281318297\n",
            "step =  17000 loss value =  0.35585655098865376\n",
            "step =  17500 loss value =  0.30903041313562374\n",
            "step =  18000 loss value =  0.2713261792401857\n",
            "step =  18500 loss value =  0.24063053861607916\n",
            "step =  19000 loss value =  0.21535819679084373\n",
            "step =  19500 loss value =  0.19432119357869432\n",
            "step =  20000 loss value =  0.1766255427369839\n",
            "step =  20500 loss value =  0.16159366341397302\n",
            "step =  21000 loss value =  0.1487075005419166\n",
            "step =  21500 loss value =  0.13756719161361985\n",
            "step =  22000 loss value =  0.12786107337899802\n",
            "step =  22500 loss value =  0.1193438522846858\n",
            "step =  23000 loss value =  0.11182062721593501\n",
            "step =  23500 loss value =  0.10513511140903248\n",
            "step =  24000 loss value =  0.09916087959426252\n",
            "step =  24500 loss value =  0.09379480767258688\n",
            "step =  25000 loss value =  0.08895211280684914\n",
            "step =  25500 loss value =  0.08456257086702562\n",
            "step =  26000 loss value =  0.08056760708299794\n",
            "step =  26500 loss value =  0.07691803969847022\n",
            "step =  27000 loss value =  0.0735723159850517\n",
            "step =  27500 loss value =  0.07049512250974323\n",
            "step =  28000 loss value =  0.06765628213530098\n",
            "step =  28500 loss value =  0.06502987238753463\n",
            "step =  29000 loss value =  0.06259351599273265\n",
            "step =  29500 loss value =  0.06032780627766267\n",
            "step =  30000 loss value =  0.058215838932787846\n",
            "\n",
            "Elapsed Time =>  0:00:40.111756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(test_data):\n",
        "    \n",
        "    z2 = np.dot(test_data, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    z3 = np.dot(a2, W3) + b3\n",
        "    y = a3 = sigmoid(z3)\n",
        "    \n",
        "    if y > 0.5:\n",
        "        pred_val = 1\n",
        "    else:\n",
        "        pred_val = 0\n",
        "\n",
        "    return y, pred_val"
      ],
      "metadata": {
        "id": "oVLKh8xTKZAW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
        "\n",
        "for input_data in test_data:\n",
        "\n",
        "    print(predict(input_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMNGiWm9KmU9",
        "outputId": "91f35674-ef52-4ea7-dfdc-d91c8a9011dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0.01223362]), 0)\n",
            "(array([0.99218744]), 1)\n",
            "(array([0.97960696]), 1)\n",
            "(array([0.01730854]), 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j36vs3QmKpsl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}